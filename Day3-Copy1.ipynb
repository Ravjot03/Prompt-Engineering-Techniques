{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3347e236-3489-4238-9ded-46148c248acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ravjotsingh/anaconda3/envs/langchain_test/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40f6c329-bd60-4cdd-985a-03fbbb00f768",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"your_api_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3a9ea96-6a16-44da-91bf-81dbb8d6b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GoogleGenerativeAI(model=\"gemini-1.5-pro\", google_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "683eb915-5771-49c6-84c7-3dc9361cdf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's tough to give a straight \"Top 10\" list because different ranking systems use different criteria. Some focus on research output, others on teaching quality, and others on factors like social mobility. \n",
      "\n",
      "However, here are 10 **highly-regarded** public universities in California that consistently rank well across various systems:\n",
      "\n",
      "**1. University of California, Berkeley (UC Berkeley)**\n",
      "* Renowned for its academic excellence, particularly in STEM fields and the humanities. \n",
      "\n",
      "**2. University of California, Los Angeles (UCLA)**\n",
      "* Highly competitive, known for its strong programs in film, television, and the arts, as well as STEM fields.\n",
      "\n",
      "**3. University of California, San Diego (UC San Diego)**\n",
      "* Strong in science, engineering, and medicine, with a growing reputation in the arts and humanities.\n",
      "\n",
      "**4. University of California, Santa Barbara (UC Santa Barbara)**\n",
      "* Beautiful campus, known for its marine biology program and strong research output.\n",
      "\n",
      "**5. University of California, Irvine (UC Irvine)**\n",
      "*  Solid reputation across disciplines, with growing recognition in areas like computer science and healthcare.\n",
      "\n",
      "**6. University of California, Davis (UC Davis)**\n",
      "*  Renowned for its veterinary medicine, agriculture, and environmental science programs.\n",
      "\n",
      "**7. University of California, Santa Cruz (UC Santa Cruz)**\n",
      "*  Known for its progressive culture, strong humanities programs, and beautiful redwood forest campus.\n",
      "\n",
      "**8. California Polytechnic State University, San Luis Obispo (Cal Poly San Luis Obispo)**\n",
      "*  Highly regarded for its engineering and architecture programs, with a focus on hands-on learning.\n",
      "\n",
      "**9. San Diego State University (SDSU)**\n",
      "*  Large, urban university with a strong business school and growing research profile.\n",
      "\n",
      "**10. California State University, Long Beach (CSULB)**\n",
      "*  Diverse student body, known for its education, engineering, and business programs.\n",
      "\n",
      "**Important Note:** This list isn't exhaustive, and other excellent public universities in California exist. The \"best\" university for you depends on your individual needs, interests, and goals.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    llm.invoke(\"Give me a list of 10 top ranked public universities in California\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "178d9be8-6eaf-47b2-9a95-1ab0a3d1312a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "top_california_public_universities = [\n",
      "    \"University of California, Berkeley\",\n",
      "    \"University of California, Los Angeles (UCLA)\",\n",
      "    \"University of California, San Diego (UCSD)\",\n",
      "    \"University of California, Santa Barbara (UCSB)\",\n",
      "    \"University of California, Irvine (UCI)\",\n",
      "    \"University of California, Davis (UC Davis)\",\n",
      "    \"University of California, Santa Cruz (UCSC)\",\n",
      "    \"University of California, Riverside (UCR)\",\n",
      "    \"California Polytechnic State University, San Luis Obispo (Cal Poly SLO)\",\n",
      "    \"San Diego State University (SDSU)\"\n",
      "]\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    llm.invoke(\"Give me a list of 10 top ranked public universities in Californi. Give me the output in a python list \")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62d459f4-166c-4e0a-9d25-bb6ef9de75ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': 'Why did the scarecrow win an award?',\n",
       " 'punchline': 'Because he was outstanding in his field!'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c3b6f37-0c59-44ca-bce8-706245a87dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "output = chain.invoke({\"query\": joke_query})\n",
    "\n",
    "print(type(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64780873-1544-4087-8675-88594d2b648a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'setup': \"Why don't scientists trust atoms?\", 'punchline': 'Because they make up everything!'}\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e42c3eff-9de2-4f5b-964d-c95f64e4e734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```python\\nmy_dict = {1: 2}\\n\\nprint(my_dict)\\n```\\n\\nThis code will output:\\n\\n```\\n{1: 2} \\n``` \\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Give me a dictionary containing 1 as key and 2 as value. and print only the dictionary in the output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3837af47-e540-4043-ac93-c72b0b7195fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't scientists trust atoms?\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['setup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f6dac9d-96d1-4ef9-a56f-88cad7f9a50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Because they make up everything!'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['punchline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d36ab20f-87ee-4a7f-8729-d64d9f282ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': ['UCLA', 'USC', 'Stanford', 'Caltech'],\n",
       " 'punchline': 'What do you call a line of people waiting to get into a UC Berkeley lecture?  A Cal queue!'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: list[str] = Field(description=\"generate list of some top universities in california\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"], \n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "output = chain.invoke({\"query\": joke_query})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02ee8d39-c36e-4a62-a26c-6405a2eeb91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output['setup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96a81468-5143-4746-8358-d1f9136c92e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCLA\n",
      "USC\n",
      "Stanford\n",
      "Caltech\n"
     ]
    }
   ],
   "source": [
    "for i in output['setup']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "187e7760-58a9-4427-b0ff-794608a4185c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'Diljit Dosanjh',\n",
       " 'Songs': ['Lover', 'G.O.A.T.', 'Clash', 'Born to Shine', 'Patiala Peg']}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    Name: str = Field(description=\"Give me a random singer\")\n",
    "    Songs: list[str] = Field(description=\"give me the list of some of his best songs\")\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"punjabi songs singer\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"], \n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "output = chain.invoke({\"query\": joke_query})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0c0dfbc-01eb-474c-b134-563eeb230500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lover\n",
      "G.O.A.T.\n",
      "Clash\n",
      "Born to Shine\n",
      "Patiala Peg\n"
     ]
    }
   ],
   "source": [
    "for i in output['Songs']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4663da0b-6f00-485b-8843-dbcaddd00ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chocolate',\n",
       " 'Vanilla',\n",
       " 'Strawberry',\n",
       " 'Mint Chocolate Chip',\n",
       " 'Cookies and Cream']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List five {subject}.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "output = chain.invoke({\"subject\": \"ice cream flavors\"})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8807bfaa-d88d-4e86-abcd-774707b9b470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chocolate\n",
      "Vanilla\n",
      "Strawberry\n",
      "Mint Chocolate Chip\n",
      "Cookies and Cream\n"
     ]
    }
   ],
   "source": [
    "for s in output:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "70d827db-2dc9-4830-a0b6-224b98d6be3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['subject'], partial_variables={'format_instructions': 'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'}, template='List five {subject}.\\n{format_instructions}')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
